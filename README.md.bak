# web_RAG

This repository demonstrates a proof of concept for using a Retrieval-Augmented Generation (RAG) system as a helper bot for websites. The goal is to assist users in retrieving information and navigating websites effectively.

The project was developed to explore the feasibility of building a website assistant bot tailored for the University of Luxembourg. It was conducted under the supervision of Prof. Martin Theobald.

## Pre-Requisites
### Hardware
This was developped on a MacBook Pro M1, running MacOs Sequoia.
In order to retrieve the websites, the chunks and their ebeddings effectively, those parts were outsourced to a VM with more computational ressources, due to the restricted RAM availability on the MacBook Pro.
This project is ensured to run on the aforementioned hardware requirements as well as the OS (depending on the size of the website/data). 
Nevertheless, it can be also run on another "modern" device capable of running Python 3.8 or newer
with no or small adjustments.
It is recommended to have at least 16GB RAM available on your system.

### Environment
The necessary dependecies and variables can be seen in the requirements.txt and the default settings
of the config file.


## Installtion

### Clone the repository
```shell
git clone https://github.com/TarikTornes/web_RAG.git

# or with using ssh
git clone git@github.com:TarikTornes/web_RAG.git
```

### Depedencies
1. Create an python environment installing all the necessary depedencies from the requirements.txt,
using either `conda` or `pip`.
2. Install the a language model of your choice. (Recommended to use Quantized Version of Llama 3.1 8B Instruct)
-> ![https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF]
```shell
pip install -U "huggingface_hub[cli]"
huggingface-cli download bartowski/Meta-Llama-3.1-8B-Instruct-GGUF --include "Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf" --local-dir ./
```
Make sure that the gguf file is located in the `/data` directory.

### Config
Ensure that you have set the config parameters appropriately depending on your environment.

## Running the Script
Make sure you are in the root directory of the repository.
In order to start the script, resp. RAG system run the following command:
```shell
./scripts/run_all.sh
```

This will ask you if you want to run the chunking script and embedding script which need to be run at least once, in order to safe it for the website defined in the config file. 
Depending on the size of the website and your hardware components 
this can take a while and can be quite ressource intensive.
Therefore it is recommended to clone the chunking and embedding branch to a more powerful system,
like a VM with multiple cores which can run over night if necessary to retrieve the webpages 
of the websites, and embed their corresponding chunks, such that you can copy the 2 outputted 
pickled files into the data directory of the repo on your local machine.





